# -*- coding: utf-8 -*-
"""clip_extractor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bgbi2mclYB7Kb1TLUQWMBpFS287VGOxe
"""

from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import requests
import torch
import pickle
from google.colab import drive
import json
from tqdm import tqdm

drive.mount('/content/gdrive')

# Load the model and processor
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# Function to get image features
def get_image_features(image_path):
    # Open the image file
    image = Image.open(image_path)

    # Process the image
    inputs = processor(images=image, return_tensors="pt")

    # Get the features from the model
    with torch.no_grad():
        outputs = model.get_image_features(**inputs)

    # Convert the tensor to numpy array
    image_features = outputs[0].cpu().numpy()
    return image_features

# image array, we need to put our images into this set
train_data_file = "/content/gdrive/MyDrive/DATA/train.pkl"
test_data_file = "/content/gdrive/MyDrive/DATA/test.pkl"

with open(train_data_file, 'rb') as f:
    data = pickle.load(f)

processed_imgs = []

#get image urls from REVIVE list of train data
for i, dict_data in enumerate(tqdm(data)):
        img_id = dict_data['image_name']
        split = img_id.split('_')[1]
        url = f"http://images.cocodataset.org/{split}/{img_id}"
        path = img_id
        processed_imgs.append((url, path))

# get and save images from coco dataset
for i, (url, path) in enumerate(tqdm(processed_imgs)):
  response = requests.get(url)
  with open(path, 'wb') as f:
      f.write(response.content)

#function for feature extraction, automatically processes all images.
def extractor (image_list) :
  image_list_array = image_list
  feature_list = []
  lst_data = []

  #get the features of every image in the list
  for i, (url, path) in enumerate(tqdm(image_list)) :
    features = get_image_features(path)
    feature_list.append(features)

    # save url and fitting features to dictionary to use for further actions
    dict = {'url': url, 'feature': features}

    #dict = {'url': url, 'feature': feature_list}
    lst_data.append(dict)

  return lst_data

# get features
dictionary_list = extractor(processed_imgs)
print("Got dictionary list: " + len(dictionary_list))


# write dictionary to pkl file to use for training and testing
fileName = 'out_data/output_features.pkl'
with open(fileName, 'wb') as out:
  pickle.dump(dictionary_list, out)
