# -*- coding: utf-8 -*-
"""clip_extractor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bgbi2mclYB7Kb1TLUQWMBpFS287VGOxe
"""

from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import requests
import torch
import pickle
from google.colab import drive
import json

drive.mount('/content/gdrive')

# Load the model and processor
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# Function to get image features
def get_image_features(image_path):
    # Open the image file
    image = Image.open(image_path)

    # Process the image
    inputs = processor(images=image, return_tensors="pt")

    # Get the features from the model
    with torch.no_grad():
        outputs = model.get_image_features(**inputs)

    # Convert the tensor to numpy array
    image_features = outputs[0].cpu().numpy()
    return image_features

# image array. we need to put our images into this set
with open("/content/gdrive/MyDrive/DATA/train.pkl", 'rb') as f:
    data = pickle.load(f)

processed_imgs = []

for i, dict_data in enumerate(data):
      #if i <10:
        img_id = dict_data['image_name']
        split = img_id.split('_')[1]
        url = f"http://images.cocodataset.org/{split}/{img_id}"
        path = img_id
        processed_imgs.append((url, path))


for i, (url, path) in enumerate(processed_imgs):
  response = requests.get(url)
  with open(path, 'wb') as f:
      f.write(response.content)

#function for feature extraction, automatically processes all images.
def extractor (image_list) :
  image_list_array = image_list
  feature_list = []
  lst_data = []
  for i, (url, path) in enumerate(image_list) :
    features = get_image_features(path)
    feature_list.append(features)

    dict = {'url': url, 'feature': feature_list}
    lst_data.append(dict)

  return lst_data

# Get features
dictionary_list = extractor(processed_imgs)

fileName = '/content/gdrive/MyDrive/DATA/A-output.pkl'
with open(fileName, 'wb') as out:
  pickle.dump(dictionary_list, out)

#with open(fileName, 'rb') as file:
#  data = pickle.load(file)

print(data)



